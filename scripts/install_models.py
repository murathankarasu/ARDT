#!/usr/bin/env python3
"""
ARDS iÃ§in gerekli AI modellerini indiren optimize edilmiÅŸ script
Kaynak dostu sÃ¼rÃ¼m - 50GB yerine ~1GB indirme
"""

import os
import sys
import requests
import urllib.request
from pathlib import Path
from tqdm import tqdm
import torch
from transformers import AutoModel, AutoProcessor
from timm import create_model
import argparse


def download_file(url: str, destination: str, description: str = ""):
    """Dosya indirme fonksiyonu"""
    print(f"ğŸ“¥ Ä°ndiriliyor: {description}")
    
    try:
        # Dosya boyutunu al
        response = requests.head(url)
        total_size = int(response.headers.get('content-length', 0))
        
        # Progress bar ile indir
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            with open(destination, 'wb') as f:
                with tqdm(total=total_size, unit='B', unit_scale=True, desc=description) as pbar:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
                        pbar.update(len(chunk))
        
        print(f"âœ… Ä°ndirildi: {destination}")
        return True
        
    except Exception as e:
        print(f"âŒ Hata: {e}")
        return False


def download_huggingface_model(model_name: str, cache_dir: str):
    """HuggingFace modeli indir"""
    try:
        print(f"ğŸ¤— HuggingFace modeli indiriliyor: {model_name}")
        
        # Model ve processor'Ä± indir
        model = AutoModel.from_pretrained(model_name, cache_dir=cache_dir)
        processor = AutoProcessor.from_pretrained(model_name, cache_dir=cache_dir)
        
        print(f"âœ… HuggingFace modeli indirildi: {model_name}")
        return True
        
    except Exception as e:
        print(f"âŒ HuggingFace model hatasÄ± ({model_name}): {e}")
        return False


def download_timm_model(model_name: str, cache_dir: str):
    """TIMM modeli indir"""
    try:
        print(f"â° TIMM modeli indiriliyor: {model_name}")
        
        # Modeli oluÅŸtur ve cache'le
        model = create_model(model_name, pretrained=True)
        
        # Model aÄŸÄ±rlÄ±klarÄ±nÄ± kaydet
        model_path = Path(cache_dir) / f"{model_name}.pth"
        torch.save(model.state_dict(), model_path)
        
        print(f"âœ… TIMM modeli indirildi: {model_name}")
        return True
        
    except Exception as e:
        print(f"âŒ TIMM model hatasÄ± ({model_name}): {e}")
        return False


def check_system_requirements():
    """Sistem gereksinimlerini kontrol et"""
    print("ğŸ” Sistem gereksinimleri kontrol ediliyor...")
    
    # Python sÃ¼rÃ¼mÃ¼
    python_version = sys.version_info
    if python_version < (3, 8):
        print("âŒ Python 3.8+ gerekli")
        return False
    
    print(f"âœ… Python {python_version.major}.{python_version.minor}")
    
    # PyTorch
    try:
        import torch
        print(f"âœ… PyTorch {torch.__version__}")
        
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            print(f"ğŸ® GPU: {gpu_name}")
        else:
            print("âš ï¸ GPU bulunamadÄ± - CPU modunda Ã§alÄ±ÅŸacak")
            
    except ImportError:
        print("âŒ PyTorch bulunamadÄ±")
        return False
    
    # Disk alanÄ±
    import shutil
    free_space = shutil.disk_usage(".").free / (1024**3)  # GB
    required_space = 2  # GB (azaltÄ±ldÄ±)
    
    if free_space < required_space:
        print(f"âŒ Yetersiz disk alanÄ±: {free_space:.1f}GB (gerekli: {required_space}GB)")
        return False
    
    print(f"âœ… Disk alanÄ±: {free_space:.1f}GB")
    
    return True


def get_model_configs():
    """Model konfigÃ¼rasyonlarÄ±nÄ± dÃ¶ndÃ¼r"""
    return {
        "ultra": {
            "name": "Ultra Hafif (DÃ¼ÅŸÃ¼k Sistem)",
            "description": "Ã‡ok dÃ¼ÅŸÃ¼k donanÄ±m iÃ§in - sadece ~50MB",
            "yolo_models": ["yolov8n"],
            "huggingface_models": [],
            "timm_models": []
        },
        "minimal": {
            "name": "Minimal (Ã‡ok Hafif)",
            "description": "Sadece temel modeller - ~200MB",
            "yolo_models": ["yolov8n"],
            "huggingface_models": [],
            "timm_models": ["efficientnet_lite0"]
        },
        "light": {
            "name": "Hafif (Ã–nerilen)",
            "description": "Dengeli performans - ~800MB",
            "yolo_models": ["yolov8n", "yolov8s"],
            "huggingface_models": ["openai/clip-vit-base-patch32"],
            "timm_models": ["efficientnet_b0"]
        },
        "medium": {
            "name": "Orta Model (3GB)",
            "description": "MEDIUM komplexity - kalite-performans dengesi ~3GB",
            "yolo_models": ["yolov8s"],
            "huggingface_models": ["openai/clip-vit-base-patch32"],
            "timm_models": ["efficientnet_b2", "resnet34"]
        },
        "standard": {
            "name": "Standart",
            "description": "Tam Ã¶zellik seti - ~1.5GB",
            "yolo_models": ["yolov8n", "yolov8s", "yolov8m"],
            "huggingface_models": ["openai/clip-vit-base-patch32"],
            "timm_models": ["efficientnet_b2", "resnet50"]
        },
        "full": {
            "name": "Tam (BÃ¼yÃ¼k Sistemler)",
            "description": "TÃ¼m modeller dahil - ~3GB",
            "yolo_models": ["yolov8n", "yolov8s", "yolov8m"],
            "huggingface_models": ["openai/clip-vit-base-patch32", "openai/clip-vit-large-patch14"],
            "timm_models": ["efficientnet_b2", "resnet50", "vit_base_patch16_224"]
        }
    }


def main():
    """Ana fonksiyon"""
    parser = argparse.ArgumentParser(description="ARDS Model Ä°ndirici")
    parser.add_argument(
        "--mode", 
        choices=["ultra", "minimal", "light", "medium", "standard", "full"], 
        default="light",
        help="Ä°ndirme modu (varsayÄ±lan: light)"
    )
    parser.add_argument(
        "--list-modes", 
        action="store_true",
        help="Mevcut modlarÄ± listele"
    )
    
    args = parser.parse_args()
    
    print("ğŸš€ ARDS - Optimize Model Ä°ndirici")
    print("=" * 60)
    
    # ModlarÄ± listele
    if args.list_modes:
        configs = get_model_configs()
        print("\nğŸ“‹ Mevcut Ä°ndirme ModlarÄ±:")
        print("-" * 40)
        for mode, config in configs.items():
            print(f"ğŸ”¹ {mode}: {config['name']}")
            print(f"   {config['description']}")
        print("\nÃ–rnek kullanÄ±m:")
        print("python scripts/install_models.py --mode minimal")
        return 0
    
    # Sistem kontrolÃ¼
    if not check_system_requirements():
        print("âŒ Sistem gereksinimleri karÅŸÄ±lanmÄ±yor")
        return 1
    
    # Model konfigÃ¼rasyonu
    configs = get_model_configs()
    selected_config = configs[args.mode]
    
    print(f"\nğŸ¯ SeÃ§ilen mod: {selected_config['name']}")
    print(f"ğŸ“– AÃ§Ä±klama: {selected_config['description']}")
    
    # KullanÄ±cÄ± onayÄ±
    response = input(f"\n{selected_config['name']} modunu indirmek istiyor musunuz? (y/N): ")
    if response.lower() not in ['y', 'yes', 'evet', 'e']:
        print("âŒ Ä°ÅŸlem iptal edildi")
        return 1
    
    # Model klasÃ¶rlerini oluÅŸtur
    models_dir = Path("models")
    pretrained_dir = models_dir / "pretrained"
    custom_dir = models_dir / "custom"
    cache_dir = models_dir / "cache"
    
    for directory in [pretrained_dir, custom_dir, cache_dir]:
        directory.mkdir(parents=True, exist_ok=True)
    
    # YOLO model URL'leri (v8.3.0 gÃ¼ncel sÃ¼rÃ¼m)
    yolo_urls = {
        "yolov8n": "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt",
        "yolov8s": "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt",
        "yolov8m": "https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt"
    }
    
    success_count = 0
    total_models = (
        len(selected_config["yolo_models"]) + 
        len(selected_config["huggingface_models"]) + 
        len(selected_config["timm_models"])
    )
    
    # YOLO modellerini indir
    print("\nğŸ“¦ YOLO Modelleri")
    print("-" * 30)
    for model_name in selected_config["yolo_models"]:
        destination = pretrained_dir / f"{model_name}.pt"
        
        if destination.exists():
            print(f"âš ï¸ Zaten mevcut: {model_name}")
            success_count += 1
            continue
        
        url = yolo_urls[model_name]
        if download_file(url, str(destination), f"{model_name} (~{get_model_size(model_name)})"):
            success_count += 1
    
    # HuggingFace modellerini indir
    if selected_config["huggingface_models"]:
        print("\nğŸ¤— HuggingFace Modelleri")
        print("-" * 30)
        for model_name in selected_config["huggingface_models"]:
            if download_huggingface_model(model_name, str(cache_dir)):
                success_count += 1
    
    # TIMM modellerini indir
    print("\nâ° TIMM Modelleri")
    print("-" * 30)
    for model_name in selected_config["timm_models"]:
        if download_timm_model(model_name, str(cache_dir)):
            success_count += 1
    
    # SonuÃ§
    print("\n" + "=" * 60)
    print(f"ğŸ“Š TamamlandÄ±: {success_count}/{total_models} model")
    
    if success_count == total_models:
        print("ğŸ‰ TÃ¼m modeller baÅŸarÄ±yla indirildi!")
        print("\nğŸš€ KullanÄ±m:")
        print("python src/main.py --mode mixed")
        
        # KonfigÃ¼rasyon Ã¶nerisi
        if args.mode == "minimal":
            print("\nğŸ’¡ Minimal mod kullanÄ±yorsunuz, mobile.yaml config dosyasÄ±nÄ± kullanÄ±n:")
            print("python src/main.py --config configs/mobile.yaml")
        elif args.mode == "light":
            print("\nğŸ’¡ Hafif mod kullanÄ±yorsunÄ±z, default ayarlar optimal Ã§alÄ±ÅŸacak")
    else:
        print("âš ï¸ BazÄ± modeller indirilemedi")
        print("ğŸ“¡ Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin")
        print("ğŸ’¾ Disk alanÄ±nÄ±zÄ± kontrol edin")
        return 1
    
    # Model dosya boyutlarÄ±
    print(f"\nğŸ“ Model klasÃ¶rÃ¼ boyutu:")
    total_size = sum(f.stat().st_size for f in models_dir.rglob('*') if f.is_file())
    print(f"Toplam: {total_size / (1024**3):.2f} GB")
    
    return 0


def get_model_size(model_name):
    """Model boyutlarÄ±nÄ± tahmin et"""
    sizes = {
        "yolov8n": "6MB",
        "yolov8s": "22MB", 
        "yolov8m": "52MB",
        "efficientnet_lite0": "20MB",
        "efficientnet_b0": "21MB",
        "efficientnet_b2": "36MB",
        "resnet50": "98MB"
    }
    return sizes.get(model_name, "bilinmiyor")


if __name__ == "__main__":
    sys.exit(main()) 